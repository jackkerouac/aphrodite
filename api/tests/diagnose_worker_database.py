#!/usr/bin/env python3
"""
Database diagnostic script for Aphrodite Worker

This script helps diagnose database connection issues for the Celery worker.
"""

import os
import sys
import asyncio
from pathlib import Path

# Add the API directory to the path
api_dir = Path(__file__).parent.parent
sys.path.insert(0, str(api_dir))

async def diagnose_database_issue():
    """Comprehensive database connection diagnosis"""
    print("ğŸ” Aphrodite Worker Database Diagnosis")
    print("=" * 50)
    
    # Print environment info
    print("\nğŸ“‹ Environment Variables:")
    env_vars = [
        'POSTGRES_HOST', 'POSTGRES_PORT', 'POSTGRES_DB', 
        'POSTGRES_USER', 'POSTGRES_PASSWORD', 'DATABASE_URL'
    ]
    for var in env_vars:
        value = os.environ.get(var, 'Not set')
        if 'PASSWORD' in var and value != 'Not set':
            value = '*' * len(value)  # Mask password
        print(f"  {var}: {value}")
    
    # Test settings loading
    print("\nâš™ï¸ Testing Settings Loading:")
    try:
        from app.core.config import get_settings
        settings = get_settings()
        print(f"  âœ… Settings loaded successfully")
        print(f"  ğŸ”— Database URL: {settings.get_database_url()}")
        
        # Test if we're in Docker
        is_docker = os.path.exists('/.dockerenv')
        print(f"  ğŸ³ Docker environment: {is_docker}")
        
    except Exception as e:
        print(f"  âŒ Settings loading failed: {e}")
        return False
    
    # Test direct database connection
    print("\nğŸ—„ï¸ Testing Database Connection:")
    try:
        from sqlalchemy.ext.asyncio import create_async_engine
        from sqlalchemy import text
        
        # Test with the exact same configuration as the worker
        engine = create_async_engine(
            settings.get_database_url(),
            echo=False,
            pool_size=1,
            max_overflow=0,
            pool_pre_ping=True
        )
        
        async with engine.begin() as conn:
            # Test basic connection
            result = await conn.execute(text("SELECT version()"))
            version = result.scalar()
            print(f"  âœ… Connection successful!")
            print(f"  ğŸ“Š PostgreSQL Version: {version}")
            
            # Test if tables exist
            result = await conn.execute(text("""
                SELECT table_name 
                FROM information_schema.tables 
                WHERE table_schema = 'public'
                ORDER BY table_name
            """))
            tables = [row[0] for row in result.fetchall()]
            print(f"  ğŸ“‹ Tables found: {', '.join(tables) if tables else 'No tables'}")
            
            # Check if alembic_version table exists
            if 'alembic_version' in tables:
                result = await conn.execute(text("SELECT version_num FROM alembic_version"))
                version_num = result.scalar()
                print(f"  ğŸ”„ Alembic version: {version_num}")
            else:
                print(f"  âš ï¸ No alembic_version table found")
            
            # Check if workflow tables exist
            workflow_tables = [t for t in tables if 'batch_job' in t or 'poster_processing' in t]
            if workflow_tables:
                print(f"  ğŸ“ Workflow tables: {', '.join(workflow_tables)}")
            else:
                print(f"  âš ï¸ No workflow tables found")
        
        await engine.dispose()
        
    except Exception as e:
        print(f"  âŒ Database connection failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # Test Celery configuration
    print("\nğŸ¥¬ Testing Celery Configuration:")
    try:
        from celery_app import celery_app
        print(f"  âœ… Celery app loaded successfully")
        print(f"  ğŸ“¡ Broker URL: {celery_app.conf.broker_url}")
        print(f"  ğŸ’¾ Result Backend: {celery_app.conf.result_backend}")
        
        # Check if the worker task is registered
        if 'app.services.workflow.workers.batch_worker.process_batch_job' in celery_app.tasks:
            print(f"  âœ… Batch worker task registered")
        else:
            print(f"  âŒ Batch worker task NOT registered")
            print(f"  ğŸ“‹ Registered tasks: {list(celery_app.tasks.keys())}")
            
    except Exception as e:
        print(f"  âŒ Celery configuration failed: {e}")
        return False
    
    # Test importing the batch worker
    print("\nğŸ”§ Testing Batch Worker Import:")
    try:
        from app.services.workflow.workers.batch_worker import process_batch_job
        print(f"  âœ… Batch worker imported successfully")
        
        # Test the worker database connection method
        print("  ğŸ” Testing worker database connection logic...")
        from app.services.workflow.workers.batch_worker import _process_batch_job_async
        
        # We won't actually run the async function, just check if it imports
        print(f"  âœ… Worker async function imported successfully")
        
    except Exception as e:
        print(f"  âŒ Batch worker import failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    print("\nğŸ‰ Database Diagnosis Complete!")
    print("=" * 50)
    return True

if __name__ == "__main__":
    success = asyncio.run(diagnose_database_issue())
    if success:
        print("\nâœ… All checks passed! Worker should be able to connect to database.")
    else:
        print("\nâŒ Some checks failed. Please review the errors above.")
    sys.exit(0 if success else 1)
