#!/usr/bin/env python3
# aphrodite.py  ‚Ä¢  stripped-down (no StateManager)

import sys
import os
import argparse
import time

# Fix Unicode encoding issues on Windows
if sys.platform == "win32":
    import codecs
    import io
    # Set UTF-8 encoding for stdout and stderr
    sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.detach(), encoding='utf-8', errors='replace')
    # Set environment variable for subprocess communication
    os.environ['PYTHONIOENCODING'] = 'utf-8'

# Apply enhanced anime mapping to production
try:
    from integrate_enhanced_anime_mapping import apply_production_enhancements
    apply_production_enhancements()
except Exception as e:
    print(f"‚ö†Ô∏è Note: Enhanced anime mapping not available: {e}")

from aphrodite_helpers.cleanup.poster_cleanup import clean_poster_directories

from aphrodite_helpers.settings_validator import run_settings_check
from aphrodite_helpers.config_auto_repair import validate_and_repair_settings
from aphrodite_helpers.check_jellyfin_connection import (
    load_settings,
    get_jellyfin_libraries,
    get_library_item_count,
    get_library_items
)
from aphrodite_helpers.get_media_info import (
    get_media_stream_info,
    get_primary_audio_codec
)
from aphrodite_helpers.get_resolution_info import (
    get_media_resolution_info,
    get_resolution_badge_text
)
from aphrodite_helpers.apply_review_badges import process_item_reviews
from aphrodite_helpers.poster_fetcher import download_poster
from aphrodite_helpers.resize_posters import resize_image
from aphrodite_helpers.apply_badge import (
    load_badge_settings,
    create_badge,
    apply_badge_to_poster
)
from aphrodite_helpers.poster_uploader import PosterUploader
from aphrodite_helpers.tv_series_aggregator import get_series_dominant_badge_info
from aphrodite_helpers.metadata_tagger import add_aphrodite_tag, MetadataTagger, get_tagging_settings

# üóÑÔ∏è PHASE 2: Database Integration imports
try:
    from aphrodite_helpers.database_integration import process_item_with_database_tracking
    DATABASE_TRACKING_AVAILABLE = True
except ImportError:
    DATABASE_TRACKING_AVAILABLE = False
    print("‚ö†Ô∏è Database tracking not available, running in legacy mode")

# üóÑÔ∏è PHASE 3: Database Commands imports
try:
    from aphrodite_helpers.database_reporter import DatabaseReporter
    from aphrodite_helpers.review_updater import ReviewUpdater
    DATABASE_COMMANDS_AVAILABLE = True
except ImportError:
    DATABASE_COMMANDS_AVAILABLE = False
    print("‚ö†Ô∏è Database commands not available")


BANNER = r"""
              _                   _ _ _       
             | |                 | (_) |      
   __ _ _ __ | |__  _ __ ___   __| |_| |_ ___ 
  / _` | '_ \| '_ \| '__/ _ \ / _` | | __/ _ \
 | (_| | |_) | | | | | | (_) | (_| | | ||  __/
  \__,_| .__/|_| |_|_|  \___/ \__,_|_|\__\___|
       | |                                    
       |_|                                    

                    v3.x.x    
"""

def display_banner() -> None:
    print(BANNER)


def _process_single_item_core(jellyfin_url: str, api_key: str, user_id: str, 
                        item_id: str, max_retries: int = 3,
                        add_audio: bool = True, add_resolution: bool = True,
                        add_reviews: bool = True, add_awards: bool = True,
                        skip_upload: bool = False, add_metadata_tag: bool = True) -> bool:
    print(f"\nüìã Processing item {item_id}")

    if not add_audio and not add_resolution and not add_reviews and not add_awards:
        print("‚ö†Ô∏è No badge types selected. At least one badge type must be enabled.")
        return False

    # Check if this is a TV series and get dominant badge info if applicable
    print(f"üîç Checking if item {item_id} is a TV series...")
    
    # Add more detailed debugging
    from aphrodite_helpers.tv_series_aggregator import get_jellyfin_item_details, is_tv_series, should_use_dominant_badges
    
    print(f"üîß Debug: Checking TV series settings...")
    tv_enabled = should_use_dominant_badges()
    print(f"üîß Debug: TV series dominant badges enabled: {tv_enabled}")
    
    if tv_enabled:
        print(f"üîß Debug: Getting item details for {item_id}...")
        item_details = get_jellyfin_item_details(jellyfin_url, api_key, user_id, item_id)
        if item_details:
            item_type = item_details.get('Type', 'Unknown')
            print(f"üîß Debug: Item type: {item_type}")
            is_series = is_tv_series(item_details)
            print(f"üîß Debug: Is TV series: {is_series}")
        else:
            print(f"üîß Debug: Failed to get item details")
    
    series_badge_info = get_series_dominant_badge_info(jellyfin_url, api_key, user_id, item_id)
    
    if series_badge_info:
        print(f"‚úÖ TV series detected: {series_badge_info['name']}")
        print(f"üìä Dominant audio codec: {series_badge_info['audio_codec']}")
        print(f"üìä Dominant resolution: {series_badge_info['resolution']}")
    else:
        print(f"‚ÑπÔ∏è Not a TV series or TV series analysis disabled")
    
    # 1. Download poster (we'll need this for any badge type)
    poster_path = download_poster(jellyfin_url, api_key, item_id)
    if not poster_path:
        print("‚ùå Failed to download poster")
        return False

    # Get item name for display purposes
    if series_badge_info:
        item_name = series_badge_info['name']
        print(f"üì∫ Processing TV series: {item_name}")
    else:
        item_info = get_media_stream_info(jellyfin_url, api_key, user_id, item_id)
        if not item_info:
            item_name = "Unknown Item"
        else:
            item_name = item_info.get('name', 'Unknown Item')

    # 1.5. Resize the poster for consistent badge placement
    os.makedirs(os.path.join(os.path.dirname(os.path.abspath(__file__)), "posters", "working"), exist_ok=True)
    
    # Path for resized poster in working directory
    resized_path = os.path.join(
        os.path.dirname(os.path.abspath(__file__)),
        "posters", "working", 
        os.path.basename(poster_path)
    )
    
    # Resize the poster to ensure consistent badge placement
    resize_success = resize_image(poster_path, resized_path, target_width=1000)
    if not resize_success:
        print("‚ö†Ô∏è Failed to resize poster, continuing with original size")
        working_poster_path = poster_path
    else:
        print("‚úÖ Resized poster to 1000px width")
        working_poster_path = resized_path
        
    # Ensure output directories exist
    os.makedirs(os.path.join(os.path.dirname(os.path.abspath(__file__)), "posters", "modified"), exist_ok=True)

    output_path = None

    # 2. Process Audio Badge if requested
    if add_audio:
        # Use series dominant codec if available, otherwise get individual item codec
        if series_badge_info:
            codec = series_badge_info['audio_codec']
            print(f"üì¢ Using dominant audio codec: {codec} for TV series {item_name}")
        else:
            # Media info for non-series items
            audio_info = get_media_stream_info(jellyfin_url, api_key, user_id, item_id)
            if not audio_info:
                print("‚ùå Failed to retrieve audio information")
                return False

            codec = get_primary_audio_codec(audio_info)
            print(f"üì¢ Found audio codec: {codec} for {item_name}")
        
        # Skip adding audio badge if codec is UNKNOWN
        if codec.upper() == "UNKNOWN":
            print("‚ö†Ô∏è Skipping audio badge as codec is unknown")
        else:
            # Create audio badge
            audio_settings = load_badge_settings("badge_settings_audio.yml")
            audio_badge = create_badge(audio_settings, codec)
            
            # Apply audio badge to poster
            output_path = apply_badge_to_poster(working_poster_path, audio_badge, audio_settings)
            if not output_path:
                print("‚ùå Failed to apply audio badge to poster")
                return False
            
            # Update working_poster_path to point to the poster with audio badge
            working_poster_path = output_path

    # 3. Process Resolution Badge if requested
    if add_resolution:
        # Use series dominant resolution if available, otherwise get individual item resolution
        if series_badge_info:
            resolution_text = series_badge_info['resolution']
            print(f"üìè Using dominant resolution: {resolution_text} for TV series {item_name}")
        else:
            # Get resolution info for non-series items
            resolution_info = get_media_resolution_info(jellyfin_url, api_key, user_id, item_id)
            if not resolution_info:
                print("‚ùå Failed to retrieve resolution information")
                return False

            resolution_text = get_resolution_badge_text(resolution_info)
            print(f"üìè Found resolution: {resolution_text} for {item_name}")

        # Skip adding resolution badge if it's UNKNOWN
        if resolution_text.upper() == "UNKNOWN":
            print("‚ö†Ô∏è Skipping resolution badge as resolution is unknown")
        else:
            # Create resolution badge
            resolution_settings = load_badge_settings("badge_settings_resolution.yml")
            resolution_badge = create_badge(resolution_settings, resolution_text)
            
            # Apply resolution badge to poster (which may already have an audio badge)
            output_path = apply_badge_to_poster(working_poster_path, resolution_badge, resolution_settings)
            if not output_path:
                print("‚ùå Failed to apply resolution badge to poster")
                return False
                
            # Update working_poster_path to point to the poster with resolution badge
            working_poster_path = output_path
    
    # 3.5. Process Awards Badge if requested
    if add_awards:
        print(f"üèÜ Checking for awards badges for {item_name}")
        from aphrodite_helpers.get_awards_info import AwardsFetcher
        
        try:
            # Load settings and check for awards
            settings = load_settings()
            awards_fetcher = AwardsFetcher(settings)
            awards_info = awards_fetcher.get_media_awards_info(jellyfin_url, api_key, user_id, item_id)
            
            if awards_info:
                award_type = awards_info['award_type']
                print(f"üèÜ Found award: {award_type} for {item_name}")
                
                # Create awards badge
                awards_settings = load_badge_settings("badge_settings_awards.yml")
                awards_badge = create_badge(awards_settings, award_type)
                
                # Apply awards badge to poster
                output_path = apply_badge_to_poster(working_poster_path, awards_badge, awards_settings)
                if not output_path:
                    print("‚ùå Failed to apply awards badge to poster")
                    # Don't return False here - awards are optional
                else:
                    # Update working_poster_path to point to the poster with awards badge
                    working_poster_path = output_path
                    print(f"‚úÖ Added {award_type} award badge")
            else:
                print(f"‚ÑπÔ∏è No awards found for {item_name}")
                
        except Exception as e:
            print(f"‚ö†Ô∏è Error processing awards badge: {e}")
            # Don't fail the entire processing for awards errors
    
    # 4. Process Review Badges if requested
    if add_reviews:
        print(f"üìä Adding review badges for {item_name}")
        # We want to add the review badges to the current version of the poster 
        # (which may already have audio and resolution badges)
        review_success = process_item_reviews(
            item_id, 
            jellyfin_url, 
            api_key, 
            user_id,
            "badge_settings_review.yml",
            "posters/modified",  # Save directly to modified directory
            working_poster_path  # Pass the current working poster path
        )
        
        if not review_success:
            print("‚ö†Ô∏è No reviews found or failed to create review badges")
        else:
            # Update output_path to point to the review badge output
            review_output_path = os.path.join(
                os.path.dirname(os.path.abspath(__file__)),
                "posters", "modified", 
                os.path.basename(working_poster_path)
            )
            
            if os.path.exists(review_output_path):
                output_path = review_output_path
                working_poster_path = output_path  # Update working path too
                print(f"‚úÖ Added review badges")
            else:
                print(f"‚ö†Ô∏è Review badges were processed but output not found at {review_output_path}")

    # 5. Upload the final modified poster (unless skipped)
    if not skip_upload:
        # Check if we have a valid output path before attempting to upload
        if not output_path:
            print("‚ö†Ô∏è No modified poster was created, skipping upload")
            return False
            
        uploader = PosterUploader(jellyfin_url, api_key, user_id)
        if not uploader.upload_poster(item_id, output_path, max_retries):
            print("‚ùå Failed to upload modified poster")
            return False
        print(f"‚úÖ Uploaded poster for: {item_name}")
    else:
        if output_path:
            print(f"üì§ Skipping upload, poster saved at: {output_path}")
        else:
            print("‚ö†Ô∏è No modified poster was created, nothing to upload")

    # 6. Add metadata tag to mark this item as processed by Aphrodite
    if output_path and add_metadata_tag:  # Only tag if we actually processed something and tagging is enabled
        print(f"üè∑Ô∏è Adding Aphrodite metadata tag...")
        tag_success = add_aphrodite_tag(jellyfin_url, api_key, user_id, item_id)  # Uses settings for tag name
        if tag_success:
            print(f"‚úÖ Added metadata tag to track processing")
        else:
            print(f"‚ö†Ô∏è Failed to add metadata tag (processing was still successful)")
    elif output_path and not add_metadata_tag:
        print(f"üè∑Ô∏è Skipping metadata tag (disabled via command line)")
    elif not output_path:
        print(f"üè∑Ô∏è Skipping metadata tag (no processing occurred)")
    
    print(f"‚úÖ Success: {item_name}")
    return True


# üóÑÔ∏è PHASE 2: Database Integration Wrapper
def process_single_item(jellyfin_url: str, api_key: str, user_id: str, 
                        item_id: str, max_retries: int = 3,
                        add_audio: bool = True, add_resolution: bool = True,
                        add_reviews: bool = True, add_awards: bool = True,
                        skip_upload: bool = False, add_metadata_tag: bool = True) -> bool:
    """
    Database-integrated wrapper for process_single_item.
    
    This function adds database tracking to the core processing function
    while maintaining full backward compatibility.
    """
    
    # Processing options for database tracking
    processing_options = {
        'audio': add_audio,
        'resolution': add_resolution,
        'reviews': add_reviews,
        'awards': add_awards
    }
    
    # Use database integration if available, otherwise fall back to core function
    if DATABASE_TRACKING_AVAILABLE:
        return process_item_with_database_tracking(
            jellyfin_url, api_key, user_id, item_id,
            processing_options,
            _process_single_item_core,
            jellyfin_url, api_key, user_id, item_id, max_retries,
            add_audio, add_resolution, add_reviews, add_awards,
            skip_upload, add_metadata_tag
        )
    else:
        # Fall back to original function without database tracking
        return _process_single_item_core(
            jellyfin_url, api_key, user_id, item_id, max_retries,
            add_audio, add_resolution, add_reviews, add_awards,
            skip_upload, add_metadata_tag
        )


def _skip_processed_legacy(items, jellyfin_url: str, api_key: str, user_id: str):
    """
    Legacy method for skipping processed items using metadata tags.
    Used as fallback when database commands are not available.
    """
    tagging_settings = get_tagging_settings()
    tag_name = tagging_settings.get('tag_name', 'aphrodite-overlay')
    tagger = MetadataTagger(jellyfin_url, api_key, user_id)
    
    original_count = len(items)
    unprocessed_items = []
    
    for item in items:
        item_id = item.get('Id')
        if not item_id:
            unprocessed_items.append(item)
            continue
            
        has_tag = tagger.check_aphrodite_tag(item_id, tag_name)
        if not has_tag:
            unprocessed_items.append(item)
    
    skipped_count = original_count - len(unprocessed_items)
    print(f"üìä Metadata tag skip: {skipped_count} already processed, {len(unprocessed_items)} remaining")
    return unprocessed_items


def process_library_items(jellyfin_url: str, api_key: str, user_id: str,
                          library_id: str, limit: int | None,
                          max_retries: int, add_audio: bool = True, 
                          add_resolution: bool = True, add_reviews: bool = True,
                          add_awards: bool = True, skip_upload: bool = False,
                          add_metadata_tag: bool = True, skip_processed: bool = False) -> None:
    items = get_library_items(jellyfin_url, api_key, user_id, library_id)
    if not items:
        print("‚ö†Ô∏è  No items found in library")
        return

    # Filter out already processed items if skip_processed is enabled
    if skip_processed:
        print(f"üîç Checking for already processed items...")
        
        # üóÑÔ∏è PHASE 3: Use database for skip-processed (much faster than API calls)
        if DATABASE_COMMANDS_AVAILABLE:
            try:
                reporter = DatabaseReporter()
                processed_item_ids = reporter.get_database_processed_items(library_id)
                reporter.close()
                
                original_count = len(items)
                unprocessed_items = []
                
                for item in items:
                    item_id = item.get('Id')
                    if item_id and item_id not in processed_item_ids:
                        unprocessed_items.append(item)
                    elif not item_id:
                        unprocessed_items.append(item)  # Include items without ID
                
                skipped_count = original_count - len(unprocessed_items)
                print(f"üìä Database-powered skip: {skipped_count} already processed, {len(unprocessed_items)} remaining")
                items = unprocessed_items
                
            except Exception as e:
                print(f"‚ö†Ô∏è Database skip failed, falling back to metadata tags: {e}")
                # Fall back to original metadata tag method
                items = _skip_processed_legacy(items, jellyfin_url, api_key, user_id)
        else:
            # Fall back to original metadata tag method
            items = _skip_processed_legacy(items, jellyfin_url, api_key, user_id)

    if limit:
        items = items[:limit]
    print(f"Found {len(items)} items to process in library")

    successful_items = 0
    failed_items = 0

    for i, item in enumerate(items, 1):
        try:
            name = item.get("Name", "Unknown")
            item_id = item["Id"]
            print(f"\n[{i}/{len(items)}] {name}")
            
            success = process_single_item(jellyfin_url, api_key, user_id,
                                item_id, max_retries, add_audio, add_resolution, 
                                add_reviews, add_awards, skip_upload, add_metadata_tag)
            
            if success:
                successful_items += 1
            else:
                failed_items += 1
                print("‚ö†Ô∏è Failed to process item, continuing with next item")
                
            # Small delay between items
            time.sleep(1)
            
        except Exception as e:
            failed_items += 1
            print(f"‚ùå Error processing item: {str(e)}")
            print("‚ö†Ô∏è Continuing with next item")
            import traceback
            print(traceback.format_exc())
            time.sleep(1)
    
    # Summary at the end
    print(f"\n‚ú® Library processing complete: {successful_items} successful, {failed_items} failed out of {len(items)} total items")



def main() -> int:
    display_banner()

    parser = argparse.ArgumentParser(
        description="Aphrodite ‚Äì Jellyfin poster badge tool (stateless)")
    sub = parser.add_subparsers(dest="cmd")

    sub.add_parser("check", help="Validate settings and Jellyfin connection")
    
    status_p = sub.add_parser("status", help="Check processing status of items in a library")
    status_p.add_argument("library_id", help="Library ID to check")
    status_p.add_argument("--tag", help="Metadata tag to check for (default: from settings)")
    status_p.add_argument("--unprocessed-only", action="store_true", help="Only show items that haven't been processed")

    cleanup_p = sub.add_parser("cleanup", help="Clean up poster directories")
    cleanup_p.add_argument("--no-modified", action="store_true", help="Don't clean the modified posters directory")
    cleanup_p.add_argument("--no-working", action="store_true", help="Don't clean the working posters directory")
    cleanup_p.add_argument("--no-original", action="store_true", help="Don't clean the original posters directory")
    cleanup_p.add_argument("--quiet", action="store_true", help="Don't print status messages")

    item_p = sub.add_parser("item", help="Process a single item")
    item_p.add_argument("item_id")
    item_p.add_argument("--retries", type=int, default=3)
    item_p.add_argument("--no-audio", action="store_true", help="Don't add audio codec badge")
    item_p.add_argument("--no-resolution", action="store_true", help="Don't add resolution badge")
    item_p.add_argument("--no-reviews", action="store_true", help="Don't add review badges")
    item_p.add_argument("--no-awards", action="store_true", help="Don't add awards badges")
    item_p.add_argument("--no-upload", action="store_true", help="Don't upload posters to Jellyfin, only save locally")
    item_p.add_argument("--no-metadata-tag", action="store_true", help="Don't add metadata tag to track processing")
    item_p.add_argument("--cleanup", action="store_true", help="Clean up poster directories after processing")

    lib_p = sub.add_parser("library", help="Process every item in a library")
    lib_p.add_argument("library_id")
    lib_p.add_argument("--limit", type=int)
    lib_p.add_argument("--retries", type=int, default=3)
    lib_p.add_argument("--no-audio", action="store_true", help="Don't add audio codec badge")
    lib_p.add_argument("--no-resolution", action="store_true", help="Don't add resolution badge")
    lib_p.add_argument("--no-reviews", action="store_true", help="Don't add review badges")
    lib_p.add_argument("--no-awards", action="store_true", help="Don't add awards badges")
    lib_p.add_argument("--no-upload", action="store_true", help="Don't upload posters to Jellyfin, only save locally")
    lib_p.add_argument("--no-metadata-tag", action="store_true", help="Don't add metadata tag to track processing")
    lib_p.add_argument("--skip-processed", action="store_true", help="Skip items that already have the aphrodite-overlay tag")
    lib_p.add_argument("--cleanup", action="store_true", help="Clean up poster directories after processing")

    # üóÑÔ∏è PHASE 3: Database Commands
    db_status_p = sub.add_parser("db-status", help="Show database processing statistics")
    db_status_p.add_argument("--library", help="Filter by library ID")
    db_status_p.add_argument("--detailed", action="store_true", help="Show detailed item list")

    check_reviews_p = sub.add_parser("check-reviews", help="Check which items need review updates")
    check_reviews_p.add_argument("library_id", help="Library ID to check")
    check_reviews_p.add_argument("--hours", type=int, default=24, help="Hours since last review check (default: 24)")
    check_reviews_p.add_argument("--update", action="store_true", help="Actually update reviews for items that need it")
    check_reviews_p.add_argument("--limit", type=int, help="Maximum number of items to update")

    reprocess_p = sub.add_parser("reprocess", help="Reprocess items based on criteria")
    reprocess_p.add_argument("--failed-only", action="store_true", help="Only reprocess failed items")
    reprocess_p.add_argument("--older-than", type=int, help="Reprocess items older than X days")
    reprocess_p.add_argument("--library", help="Library ID to process")
    reprocess_p.add_argument("--limit", type=int, help="Maximum number of items to reprocess")
    reprocess_p.add_argument("--dry-run", action="store_true", help="Show what would be reprocessed without actually doing it")

    args = parser.parse_args()
    
    # Auto-repair settings before validation
    print("üîß Auto-repairing settings file...")
    validate_and_repair_settings()
    
    run_settings_check()

    settings = load_settings()
    if not settings:
        print("‚ùå Failed to load settings")
        return 1
    jf = settings["api_keys"]["Jellyfin"][0]
    url, api_key, user_id = jf["url"], jf["api_key"], jf["user_id"]

    if args.cmd == "check":
        print(f"üì° Connecting to Jellyfin at {url}")
        libs = get_jellyfin_libraries(url, api_key, user_id)
        for lib in libs:
            print(f"  - {lib['Name']} ({lib['Id']}): "
                  f"{get_library_item_count(url, api_key, user_id, lib['Id'])} items")
        # Clean up posters if requested
        if hasattr(args, 'cleanup') and args.cleanup:
            print("\nüßπ Cleaning up poster directories...")
            clean_poster_directories(
                clean_modified=True,
                clean_working=True,
                clean_original=True,
                verbose=True
            )
            
        return 0
    
    if args.cmd == "status":
        from aphrodite_helpers.metadata_tagger import MetadataTagger, get_tagging_settings
        
        print(f"üìä Checking processing status for library {args.library_id}")
        
        # Get tag from settings if not specified
        tag_to_check = args.tag
        if tag_to_check is None:
            tagging_settings = get_tagging_settings()
            tag_to_check = tagging_settings.get('tag_name', 'aphrodite-overlay')
        
        # Get all items in the library
        items = get_library_items(url, api_key, user_id, args.library_id)
        if not items:
            print("‚ö†Ô∏è  No items found in library")
            return 1
        
        tagger = MetadataTagger(url, api_key, user_id)
        processed_count = 0
        unprocessed_count = 0
        
        print(f"\nProcessing status for {len(items)} items:")
        print(f"Tag: '{tag_to_check}'\n")
        
        for item in items:
            item_id = item.get('Id')
            item_name = item.get('Name', 'Unknown')
            
            if not item_id:
                continue
                
            has_tag = tagger.check_aphrodite_tag(item_id, tag_to_check)
            
            if has_tag:
                processed_count += 1
                if not args.unprocessed_only:
                    print(f"‚úÖ {item_name} (Processed)")
            else:
                unprocessed_count += 1
                print(f"‚ö™ {item_name} (Not processed)")
        
        print(f"\nüìà Summary:")
        print(f"  Processed: {processed_count}/{len(items)} ({processed_count/len(items)*100:.1f}%)")
        print(f"  Unprocessed: {unprocessed_count}/{len(items)} ({unprocessed_count/len(items)*100:.1f}%)")
        
        return 0
        
    if args.cmd == "cleanup":
        # Invert the no-* arguments for the clean_* parameters
        clean_modified = not (hasattr(args, 'no_modified') and args.no_modified)
        clean_working = not (hasattr(args, 'no_working') and args.no_working)
        clean_original = not (hasattr(args, 'no_original') and args.no_original)
        verbose = not (hasattr(args, 'quiet') and args.quiet)
        
        success, message = clean_poster_directories(
            clean_modified=clean_modified,
            clean_working=clean_working,
            clean_original=clean_original,
            verbose=verbose
        )
        return 0 if success else 1

    if args.cmd == "item":
        # By default, all badge types are ON
        add_audio = not (hasattr(args, 'no_audio') and args.no_audio)
        add_resolution = not (hasattr(args, 'no_resolution') and args.no_resolution)
        add_reviews = not (hasattr(args, 'no_reviews') and args.no_reviews)
        add_awards = not (hasattr(args, 'no_awards') and args.no_awards)
        skip_upload = hasattr(args, 'no_upload') and args.no_upload
        add_metadata_tag = not (hasattr(args, 'no_metadata_tag') and args.no_metadata_tag)
        
        ok = process_single_item(
            url, api_key, user_id, args.item_id, args.retries,
            add_audio=add_audio, add_resolution=add_resolution,
            add_reviews=add_reviews, add_awards=add_awards,
            skip_upload=skip_upload, add_metadata_tag=add_metadata_tag
        )
        # Clean up posters if requested
        if hasattr(args, 'cleanup') and args.cleanup:
            print("\nüßπ Cleaning up poster directories...")
            clean_poster_directories(
                clean_modified=True,
                clean_working=True,
                clean_original=True,
                verbose=True
            )
            
        return 0 if ok else 1

    if args.cmd == "library":
        # By default, all badge types are ON
        add_audio = not (hasattr(args, 'no_audio') and args.no_audio)
        add_resolution = not (hasattr(args, 'no_resolution') and args.no_resolution)
        add_reviews = not (hasattr(args, 'no_reviews') and args.no_reviews)
        add_awards = not (hasattr(args, 'no_awards') and args.no_awards)
        skip_upload = hasattr(args, 'no_upload') and args.no_upload
        add_metadata_tag = not (hasattr(args, 'no_metadata_tag') and args.no_metadata_tag)
        skip_processed = hasattr(args, 'skip_processed') and args.skip_processed
        
        process_library_items(
            url, api_key, user_id, args.library_id, args.limit, args.retries,
            add_audio=add_audio, add_resolution=add_resolution,
            add_reviews=add_reviews, add_awards=add_awards,
            skip_upload=skip_upload, add_metadata_tag=add_metadata_tag,
            skip_processed=skip_processed
        )
        return 0

    # üóÑÔ∏è PHASE 3: Database Command Handlers
    if args.cmd == "db-status":
        if not DATABASE_COMMANDS_AVAILABLE:
            print("‚ùå Database commands not available. Please check Phase 3 installation.")
            return 1
        
        try:
            reporter = DatabaseReporter()
            reporter.print_status_report(library_id=args.library, detailed=args.detailed)
            reporter.close()
        except Exception as e:
            print(f"‚ùå Error generating database status: {e}")
            return 1
        return 0
    
    if args.cmd == "check-reviews":
        if not DATABASE_COMMANDS_AVAILABLE:
            print("‚ùå Database commands not available. Please check Phase 3 installation.")
            return 1
        
        try:
            updater = ReviewUpdater(url, api_key, user_id)
            
            if args.update:
                # Actually update reviews
                items_needing_update = updater.check_items_needing_review_update(
                    args.library_id, args.hours
                )
                
                if not items_needing_update:
                    print("‚úÖ All items have current review data")
                else:
                    item_ids = [item['jellyfin_item_id'] for item in items_needing_update]
                    if args.limit:
                        item_ids = item_ids[:args.limit]
                    
                    print(f"üîÑ Updating reviews for {len(item_ids)} items...")
                    stats = updater.bulk_update_reviews(item_ids, rate_limit_seconds=1.5, max_items=args.limit)
                    print(f"\nüìä Update complete: {stats['successful']} successful, {stats['failed']} failed")
            else:
                # Just show summary
                summary = updater.get_review_update_summary(args.library_id, args.hours)
                
                print(f"\nüìä REVIEW UPDATE SUMMARY for Library {args.library_id}")
                print(f"üïí Threshold: {args.hours} hours")
                print(f"üìã Total items needing update: {summary['total_items']}")
                print("\nüìÇ Breakdown:")
                print(f"  ‚Ä¢ Never checked: {summary['categories']['never_checked']}")
                print(f"  ‚Ä¢ Very stale (>7d): {summary['categories']['very_stale']}")
                print(f"  ‚Ä¢ Stale (>1d): {summary['categories']['stale']}")
                print(f"  ‚Ä¢ Recent: {summary['categories']['recent']}")
                
                if summary['total_items'] > 0:
                    print(f"\nüí° Run with --update to actually update these {summary['total_items']} items")
            
            updater.close()
        except Exception as e:
            print(f"‚ùå Error checking reviews: {e}")
            return 1
        return 0
    
    if args.cmd == "reprocess":
        if not DATABASE_COMMANDS_AVAILABLE:
            print("‚ùå Database commands not available. Please check Phase 3 installation.")
            return 1
        
        try:
            reporter = DatabaseReporter()
            
            # Get items that meet reprocessing criteria
            items_to_reprocess = reporter.get_items_for_reprocessing(
                failed_only=args.failed_only,
                older_than_days=args.older_than,
                library_id=args.library
            )
            
            if args.limit:
                items_to_reprocess = items_to_reprocess[:args.limit]
            
            reporter.close()
            
            if not items_to_reprocess:
                print("‚úÖ No items found matching reprocessing criteria")
                return 0
            
            print(f"\nüìã Found {len(items_to_reprocess)} items matching criteria:")
            for i, item in enumerate(items_to_reprocess[:10], 1):  # Show first 10
                status_icon = "‚ùå" if item['status'] == 'failed' else "‚ö†Ô∏è"
                print(f"  {i}. {status_icon} {item['title']} ({item['type']}) - {item['status']}")
            
            if len(items_to_reprocess) > 10:
                print(f"  ... and {len(items_to_reprocess) - 10} more items")
            
            if args.dry_run:
                print(f"\nüîç DRY RUN: Would reprocess {len(items_to_reprocess)} items")
                return 0
            
            # Ask for confirmation
            print(f"\n‚ö†Ô∏è  This will reprocess {len(items_to_reprocess)} items.")
            confirm = input("Continue? (y/N): ").lower().strip()
            if confirm != 'y':
                print("‚ùå Reprocessing cancelled")
                return 0
            
            # Process items
            print(f"\nüöÄ Starting reprocessing of {len(items_to_reprocess)} items...")
            successful = 0
            failed = 0
            
            for i, item in enumerate(items_to_reprocess, 1):
                print(f"\n[{i}/{len(items_to_reprocess)}] Reprocessing: {item['title']}")
                
                # Determine badge settings (use defaults for reprocessing)
                success = process_single_item(
                    url, api_key, user_id, item['item_id'], max_retries=3,
                    add_audio=True, add_resolution=True, add_reviews=True, add_awards=True,
                    skip_upload=False, add_metadata_tag=True
                )
                
                if success:
                    successful += 1
                    print("‚úÖ Success")
                else:
                    failed += 1
                    print("‚ùå Failed")
                
                # Small delay between items
                time.sleep(1)
            
            print(f"\nüìä Reprocessing complete: {successful} successful, {failed} failed")
        
        except Exception as e:
            print(f"‚ùå Error during reprocessing: {e}")
            return 1
        return 0

    parser.print_help()
    return 0


if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        sys.exit(130)
